\documentclass[12pt]{article}
\usepackage{Sweave}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{longtable}

\usepackage[authoryear,round,comma]{natbib}
\bibliographystyle{apa}

%\VignetteIndexEntry{About the Sweavetest package}

% The next line is needed for inverse search...
\SweaveOpts{echo=TRUE,results=verbatim} % to show R code and results
\SweaveOpts{concordance=TRUE, keep.source=TRUE,echo=FALSE,results=tex}
<<>>=
options(width=60)
set.seed(18)
library(Sweavetest)
randomize <- TRUE
testversion <- 1
newCommands(thesection=FALSE)
@

\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}

% These commands affect the display of the test samples
\newcommand{\Correct}{*}
\renewcommand{\labelenumii}{(\Alph{enumii})}

\title{The \pkg{Sweavetest} Package\footnote{This 
vignette  was built using \pkg{Sweavetest} version \Sexpr{packageDescription("Sweavetest")$Version}}.}%$

\author{Duncan Murdoch \and Adam Rahman}

\begin{document}

\maketitle

\abstract{

Multiple choice tests are used frequently to assess student
performance in large classes. The \pkg{Sweavetest} package
contains support functions to format, grade and analyze multiple
choice tests.  Answers are randomized during formatting,
and after grading a report is automatically generated, showing descriptive
statistics, measuring test reliability, and presenting item analysis.
Errors in answer keys and poorly worded questions are easily
recognized through the information generated. Several plots are also
created to visually show the instructor how well the students are
performing, and to help identify possible problem questions
and answer patterns that suggest cheating.
}


\tableofcontents

\section{Introduction}

The \pkg{Sweavetest} package is designed to support administration of multiple choice
tests.  It was written at the University of Western Ontario (UWO), and some aspects of the code
reflect the way we administer tests, but efforts have been made to make it more generally
useful.

There are four main parts to the package, described in the following sections.  First, a
number of functions are given to help an instructor prepare a test using Sweave \citep{Leisch2002}.
These are described in section \ref{sec:preparing}.  At UWO, the students use Scantron brand 
mark-sense sheets to record answers on multiple-choice tests; section \ref{sec:reading}
describes how these are handled in \pkg{Sweavetest}, producing grades for each student
and merging them into existing class lists.

An important part of testing is to analyze the results of a test.  This can detect badly
worded questions, errors in answer keys, and can otherwise give information about the
quality of the questions and of the test as a whole.  Section \ref{sec:analysis} describes
this aspect of \pkg{Sweavetest}.  It may also be possible to use the aggregate results
to detect cheating by individual students; section \ref{sec:cheating} describes how this is done.
This paper finishes with a short discussion of plans for changes to \pkg{Sweavetest}.


\section{Preparing a Test}
\label{sec:preparing}

\pkg{Sweavetest} was originally designed to support writing multiple choice tests in Sweave
and \LaTeX.  There are functions that output introductory material at the start of the
test, as well as functions that format and randomize the answers.  These functions also
record the results of the randomization so that an answer key can be produced automatically
at the end.

Using the test preparation functions requires knowledge of Sweave and \LaTeX.  Instructors
who want to use other document preparation systems to produce the test can skip this section,
but some of the work done here automatically will have to be done manually later.

\subsection{Writing questions}
\label{sec:questions}

The general format of a question is assumed to be text followed by an enumerated list of 
possible responses.  \pkg{Sweavetest} supports four separate versions of each test; questions
may contain from 2 to 5 answers.

The supplied functions do the work of formatting the answers.   For example,
\begin{verbatim}
 \item Let $U \sim \Unif(0,1)$.  Set $X$ equal to 0 if 
 $U > 0.3$, equal to 1 otherwise.  The distribution of 
 $X$ is
 <<>>=
 enumerate("Binomial$(n=1, p=0.7)$", 
      "Binomial$(n=1, p=0.3)$",
      "Poisson$(\\mu = 0.3)$",
      "Poisson$(\\mu = 0.7)$",
      "Exponential$(\\lambda=0.3)$",
      Correct=2)
 @
 \end{verbatim}
The \verb!enumerate()! function produces
an enumeration environment in \LaTeX.  The answers are displayed in a random order.  Earlier in the text, we've used
\begin{verbatim}
\newcommand{\Correct}{*}
\renewcommand{\labelenumii}{(\Alph{enumii})}
\end{verbatim}
so that the correct answer is marked with an asterisk, and the answers are labelled with 
capital letters.  (We wouldn't label the correct answer on the version of the test we give to 
students!)  We also used \verb!\SweaveOpts{echo=FALSE,results=tex}! earlier to set the defaults
to output \LaTeX\ code without echoing the input.   With this preparation, the Sweave code listed
above will be processed and displayed as
\begin{enumerate}
\item Let $U \sim \Unif(0,1)$.  Set $X$ equal to 0 if $U > 0.3$, equal to 1 otherwise.  The
distribution of $X$ is
<<>>=
enumerate("Binomial$(n=1, p=0.7)$", 
      "Binomial$(n=1, p=0.3)$",
      "Poisson$(\\mu = 0.3)$",
      "Poisson$(\\mu = 0.7)$",
      "Exponential$(\\lambda=0.3)$",
      Correct=2)
@
\end{enumerate}

Besides \verb!enumerate()!, several other functions produce randomized answer lists.  The
\verb!horiz()! function formats them horizontally on a single line.  The \verb!items()! function
is like \verb!enumerate()!, but only the \LaTeX\ \verb!\items! part of the enumeration is output:
it is assumed that the test writer has already entered \verb!\begin{enumerate}! or equivalent.
The \verb!things()! function just randomizes the items it is given; the test writing needs to
enter the \verb!\item! values if necessary.

The \pkg{Sweavetest} package also has special support for questions
involving R code. \verb!Renumerate()!, \verb!Rhoriz()! and 
\verb!Ritems()! format text to look like R input expressions. The 
\verb!resultenumerate()! and \verb!resultitems()! function evaluate the
arguments and format the output as if it was printed as output by R,
unless they are protected by being wrapped in the \verb!msg()! function.
For example, the input
\begin{verbatim}
 \item Which of the following gives the best approximation to 
 $\int_0^5 (x + 4) \cos(x) dx$?
 <<>>=
 Renumerate(Correct=2,
 "x <- runif(1000, 0, 5); mean((x + 4)*cos(x))",
 "x <- runif(1000, 0, 5); mean(5*(x + 4)*cos(x))",
 "x <- runif(1000, 0, 5); mean((x + 4)*cos(x)/5)",
 "x <- rcos(1000, 0, 5); mean(x + 4)",
 "42")
 @
\end{verbatim}
produces
\begin{enumerate}
\setcounter{enumi}{1}
\item Which of the following gives the best approximation to \\
 $\int_0^5 (x + 4) \cos(x) dx$?
<<>>=
 Renumerate(Correct=2,
 "x <- runif(1000, 0, 5); mean((x + 4)*cos(x))",
 "x <- runif(1000, 0, 5); mean(5*(x + 4)*cos(x))",
 "x <- runif(1000, 0, 5); mean((x + 4)*cos(x)/5)",
 "x <- rcos(1000, 0, 5); mean(x + 4)",
 "42")
@ 
\end{enumerate}
and 
\begin{verbatim}
 \item What will the following code produce?
 <<results=hide,echo=TRUE>>=
 x <- rep(c(TRUE, FALSE), 2)
 y <- rep(c(TRUE, FALSE), each=2)
 x & !y
 @
 <<>>=
 resultenumerate(Correct=1, KeepLast=1, x & !y, x & y,
 x | !y, x | y, msg("None of the above"))
 @
\end{verbatim}

\begin{enumerate}
\setcounter{enumi}{2}
\item What will the following code produce?
<<results=hide,echo=TRUE>>=
x <- rep(c(TRUE, FALSE), 2)
y <- rep(c(TRUE, FALSE), each=2)
x & !y
@
<<>>=
resultenumerate(Correct=1, KeepLast=1,
x & !y,
x & y,
x | !y,
x | y,
msg("None of the above"))
@
\end{enumerate}

\subsection{Introductory material at start of test}

Several functions and variables are included that are intended to be run or set 
at the start of a test.  These customize the behaviour of \pkg{Sweavetest}, and 
provide some common definitions that may be helpful in producing a test.

\begin{table}
\caption{Current math mode definitions provided by \texttt{newCommands()}.\label{tab:commands}}
\begin{center}
\begin{tabular}{lc}
\hline
Macro & Sample \\
\hline
<<>>=
n <- names(formals(newCommands))
for(i in n) {
  if (!(i %in% c("Marks", "thesection", "lowtilde")))
    cat("\\verb!\\", i, "! & $ \\", i, " $ \\\\ \n", sep="")
}
@
\hline
\end{tabular}
\end{center}
\end{table}
The \verb!newCommands()! function defines a number of \LaTeX\ macros that may be
convenient to use in the test.  Current definitions of simple macros
to use in mathematical expressions are shown in Table \ref{tab:commands}.  The function
also optionally defines \verb!\Marks!, which displays marks for a question in the right
margin, \verb!\thesection!, which suppresses section numbering, and \verb!\lowtilde!,
which draws a tilde under a math symbol, similar to the convention used on a blackboard
to indicate a vector.  By default, all macros are defined, but any of them
may be suppressed by passing an argument to \verb!newCommands()!.  For example,
this document uses \verb!newCommands(thesection = FALSE)!, because section headings
should not be overridden.

The \verb!marklist()! function outputs a box, suitable for recording marks on the
first page of a test.  For example,
<<marklist, echo=TRUE, eval=FALSE>>=
marklist(marks=rep(5,4), names=1:4)
@
produces the text and box shown in Figure \ref{fig:marklist}.
\begin{figure}
\begin{center}
<<>>=
<<marklist>>
@
\end{center}
\caption{Sample mark list produced by the \texttt{marklist()} function. \label{fig:marklist}}
\end{figure}

Similarly, the \verb!multiplechoice()! function produces a box
suitable for manually entering multiple choice answers.  This would be
used on a test that only had a few multiple choice questions (Figure \ref{fig:multiplechoice}).
\begin{figure}
\begin{center}
<<>>=
multiplechoice(1:10)
@
\end{center}
\caption{Multiple choice response box produced by \texttt{multiplechoice(1:10)}. \label{fig:multiplechoice}}
\end{figure}

\subsection{Producing an answer key}

A side effect of using the functions described in section \ref{sec:questions} is that information on the
randomization is saved
and is used to produce an answer key.  For example, the answer key from the questions
above is requested via

\noindent\verb!Answer key for version \Sexpr!\verb!{versioncodes[testversion]}:\\!
\begin{verbatim}
 <<>>=
 answerkey(symbols=LETTERS)
 @
\end{verbatim}
and displayed as \\

Answer key for version \Sexpr{versioncodes[testversion]}:\\
<<>>=
answerkey(symbols=LETTERS)
@

\section{Reading Student Responses}
\label{sec:reading}

\section{Analysis of a Test}
\label{sec:analysis}

The report uses the \pkg{tables} package \citep{pkg:tables}. This section will discuss the individual analysis tools used
during the report creation process. The actual report creation process is discussed in the next section.

Using the results of the \verb!readScanex()! and the \verb!grades()! functions, a report analyzing the test as a whole
and each question individually can be easily created. The functions are called by using:

\begin{verbatim}
<<<>>=
scanex <- readScanex(''sample.dat'')
GradedTests <- grades(scanex)
@
\end{verbatim}

There are several individual functions that are used during the report creation process. Each is discussed below.

\subsection{Statistical Overview}

First, the report process creates a statistical overview of the test using the \verb!StatisticalOverview()! function.
This function is called very simply, taking only the result of the \verb!grades()! function as input:

\begin{verbatim}
StatisticalOverview(GradedTests)
\end{verbatim}

This function is used primarily for formatting in \LaTeX, utilizing the \pkg{tables} package to format the created tables
and called functions. 

When called, this package creates several statistics which analyze the overall quality of the test:

\begin{itemize}
\item Descriptive Statistics Table
\item Student Count Table
\item Test Means Table
\item Kuder-Richardson 20 Statistic
\item Ferguson's Delta
\item Answer Correlation Plot
\item Histogram of Student Scores
\end{itemize}

\subsection{Descriptive Statistics}

The descriptive statistics table is created within the \verb!StatisticalOverview()! function and includes each of the following statistics
based on the results of the test:

\begin{itemize}
\item Mean
\item Standard Deviation
\item Maximum Score
\item Minimum Score
\item 25th Quantile
\item Median
\item 75th Quantile
\end{itemize}

The table presents these statistics seperated by class section (if there is more than one section) and also presents them aggregated.
\LaTeX formatting is done using the \pkg{tables} package.

\subsection{Student Count Table}

The student count table provides a count of the number of students who wrote each different version of the exam, separated into class section
and aggregated, providing a total count for each exam code, and a grand total. This is produced automatically when the \verb!StatisticalOverview()!
function is called, with \LaTeX formatting using the \pkg{tables} package.

\subsection{Kuder-Richardson 20}

The Kuder-Richardson 20 statistics is produced by calling the \verb!KR20()! function, available in the \pkg{Sweavetest} package.
It uses the result of \verb!grades()! as input and can be called as follows:

\begin{verbatim}
<<>>=
KR20(GradedTests)
@
\end{verbatim}

This is a well known statistic that measures the internal reliability of the test. It measures how consistently the items on the 
test provide information about the knowledge of the students on the tested material.

It is calculated through the following simple formula:

\[\alpha = \frac{K}{K+1}(1- \frac{\sum_{i=1}^{K} p_{i}q_{i}}{\sigma^{2}_{X}} \]

where K is the total number of items and \[p_{i}\] is the probability of success on item i.

\subsection{Ferguson's Delta}

The Ferguson's Delta statistic is produced by calling the \verb!FergusonsDelta()! function, available in the \pkg{Sweavetest} package.
It takes the results of \verb!grades! as input, and can be called by the user as follows:

\begin{verbatim}
<<>>=
FergusonsDelta(GradedTests)
@
\end{verbatim}

Similar to the KR20 statistic, Ferguson's Delta also measures the consistency of the test. However, instead of measuring internal
reliability, it measures test reliability as ``the ratio between the number of discriminations made by the test to the greatest number
of discriminations that the test can generate, given the size of the sample and the number of items'' (Kline, 1986). 

It is calculated using the following easy formula:

\[ \delta = \frac{(m+1)(n^{2}-\sum(f^{2}_{s}}{mn^{2}}\]

where n is the number of test takers, m is the number of items, and \[f_{s}\] is the number of test takers obtaining each possible test score.

Both the Ferguson's Delta and Kuder-Richardson 20 statistics are formatted into a table using the \pkg{tables} package.

\subsection{Answer Correlation Plot}

% % % % %Dr. Murdoch to Fill In % % % % % % % %

\subsection{Score Distribution}

The \verb!StatisticalOverview()! function also produces a histogram of the scores achieved by the students on the test.
The purpose of this plot is to show the instructor the distribution of his test scores, and to help identify possible
problems with the test as a whole (when used in conjunction with the other statistics provided).

It is created as follows in the \verb!StatisticalOverview()! function:

\begin{verbatim}
weight <- max(seq_len(max(nchar(GradedTests$Correct))))
Percentage <- 100*GradedTests$Grade/weight
GradeHistogram <- hist(Percentage, main="Histogram of Student Scores", breaks = c(0,10,20,30,40,50,60,70,80,90,100))
\end{verbatim}

\subsection{Individual Question Analysis}

The \pkg{Sweavtest} package also analyzes each question individually, providing a number of useful statistics to aid in the 
recognition of potential problem questions. This includes questions that have been keyed incorrectly, questions that have
more than one plausible answer, questions that are misleading or ambiguous, and questions that may simply be too difficult.

Analysis is accomplished using the following statistics:

\begin{itemize}
\item Difficulty Rating
\item Item Discrimination
\item Point Biserial Correlation
\item Option Frequency
\item Distractor Discrimination
\item Option Frequency Plot
\item Empirical Probability Plot
\end{itemize}

Each of these items will be discussed in detail.

\subsection{Difficulty Rating}

Difficulty rating measures the number of respondents who answered the question correctly,
as a percentage of all respondents. The formula for difficulty rating is very simple:

\[ Difficulty Rating = \frac{C}{W + C} \]

where C is the number of correct respondents, and W is the number of wrong respondents.

Difficulty rating can be easily calculated using the built in function \verb!DifficultyRating()!.
It takes the result of the \verb!grades()! function discussed above, and can be called as follows:

\begin{verbatim}

DifficultyRating(GradedTests)

\end{verbatim} 

The function produces the output as follows:

% % % INSERT EXAMPLE OUTPUT % % %

A question with a difficulty rating less than .2, or greater than .8 should be reviewed by the instructor.

\subsection{Item Discrimination}

Item discrimination is used to determine if the question adequately distinguishes between those
students who have the required knowledge to answer the question and those who don't. It is calculated
very simply using the following formula:

\[ Item Discrimination = \frac{(Upper 25\% Correct) - (Lower 25\% Correct)}{Total Number of Respondents} \]

Where the upper 25\% of the students are defined to be those students who scored in the top 25\% on the test and got the question correct.
The lower 25\% of students are defined similarly.

Item discrimination can be calculated using the \verb!ItemDiscrimination()! function. It takes as input
the results of the \verb!grades()! function and can be called using the following syntax:

\begin{verbatim}
ItemDiscrimination(GradedTests)
\end{verbatim}

The function provides the following output:

% % %INSERT EXAMPLE OUTPUT % % %

A question with a negative item discrimination value should be reviewed by the instructor.

\subsection{Point Biserial Correlation}

Point biserial correlation is also a measure of test discrimination. It is easily calculated through
the following formula:

\[ Point Biserial = \frac{M_{p} - M_{q}}{\sigma\sqrt{pq}} \]

where:

\begin{itemize}
\item \[M_{p}\] is the mean score of students answering the question correctly
\item \[M_{q{}\] is the mean score of students answering the question incorrectly
\item \[\sigma\] is the standard deviation of the exam mean
\item p is the proportion of students answering the question correctly
\item q is the proportion of students answering the question incorrectly
\end{itemize}

Point biserial correlation can be easily calculated using the \verb!PointBiserial()! function
included in the \pkg{Sweavetest} package. It takes as input the results of the \verb!grades()! function,
and is called using the following syntax:

\begin{verbatim}
PointBiserial(GradedTests)
\end{verbatim}

The function provides the following output:

% % %INSERT EXAMPLE OURTPUT % % %

Point biserial correlation should be used in conjunction with the calculated item discrimination
statistic to determine if a question adequately discriminates between those students who have the
required knowledge and those who don't.

Any question with a point biserial value below .2 should be reviewed by the instructor. 

\subsection{Option Frequency}

Using the results of the \verb!CreateIndex()! function, a count of how many students chose
each answer option is provided. This will aid the instructor in determining which answer choices were the
most popular amongst the students, and which were the least popular.

Any answer option which has very few respondents should be reviewed by the instructor.

\subsection{Distractor Discrimination}

An item discrimination value is also calculated for each of the answer options. This is accomplished
in the exact same way as described above (where it is done for the entire test). Ideally, the only 
answer option with a positive item discrimination value will be the correct answer. All other options
should have a negative item discrimination value, which tells the instructor that the students who scored
lowest on the test are choosing that option more frequently than the students who scored highest on the test.

Any incorrect answer with a positive item discrimination should be evaluated by the instructor.

\subsection{Option Frequency Plot}

The option frequency plot provides a way for the instructor to visualise which questions were most popular
amongst the test takers. Frequencies are provided as boxes, and are separated by exam code (if more than one
is given). The boxes of the correct answers are white, while the boxes of incorrect answers are shaded red.

The plot is created by calling the function \verb!answerPlots()!. This function takes as input a matrix of the
students' answers, a matrix of the corresponding correct answers, a vector of exam codes, and the question number
of the plot to be produced. For example, the following will produce an option frequency plot for the first question
of our sample data:

\begin{verbatim}
StudentAnswers <- GradedTests$Answers
CorrectAnswers <- GradedTests$Correct
ExamVersion <- GradedTests$ExamCode
QuestionCounter <- 1

answerPlots(StudentAnswers, CorrectAnswers, ExamVersion, QuestionCounter)
\end{verbatim}

% % %INSERT EXAMPLE PLOT % % %

\subsection{Empirical Probability Plot}

The empirical probability plot represents the cumulative distribution function for the probability of
answering the question correctly. It plots the test scores along the x-axis and the probability that
the test taker will answer the question correctly along the y-axis.

From this graph, we can deduce the empirical probability of a student answering the question correctly
given his score on the test.

It would be expected that this graph would be monotonically increasing, from the lowest score achieved on
the test to the highest score.

The plot can be created using the \verb!EmpiricalProbabilityPlot()! function. It takes as input the results
from the \verb!grades()! function, as well as the question number for which the plot will created. A plot
for the first question can be created using the following syntax:

\begin{verbatim}
QuestionCounter <- 1
EmpiricalProbabilityPlot(GradedTests, QuestionCounter)
\end{verbatim}

Yielding the following graph:

% % %INPUT EXAMPLE OUTPUT % % %

A question in which the plot exhibits a decreasing trend overall as opposed to an increasing trend should
be reviewed by the instructor.

\subsection{Warnings}

Part of the analysis of the multiple choice test is providing the instructor with information on the
appropriateness of the calculated values of the statistics. If the values of the Item Discrimination, 
Difficulty Rating, or Point Biserial statistics fall below industry standards, 
the built in function \verb!Warnings{}! will automatically produce a message informing the instructor,
as well as pointing the instructor to resources with suggestions on improving (or possibly eliminating) 
said question.

Warnings are produced if any combination of the following occur:

\begin{itemize}
\item The item discrimination statistic falls below 0
\item The difficulty rating falls below 0.2
\item The point biserial correlation falls below 0.2
\end{itemize}

The \verb!Warnings()! function takes the calculated values of the item discrimination, difficulty
rating, and point biserial correlation as inputs. The syntax is as follows:

\begin{verbatim}
DR <- DifficultyRating(GradedTests)
ID <- ItemDiscrimination(GradedTests)
PB <- PointBiserial(GradedTests)

Warnings(DR, ID, PB)
\end{verbatim}

A number of different outputs can be produced dependent upon which statistics are at unacceptable
levels. A couple examples are given below:

% % %Insert Examples % % %

The report also provides warning messages if the Kuder-Richardson 20 statistic or Ferguson's Delta
fall below acceptable standards. These messages are produced directly by the \verb!StatisticalOverview()!
function.

Warnings are produced if the KR20 statistic falls below 0.7 or Ferguson's Delta falls below 0.9 and are 
given on the Statistical Overview page.

\section{Report Creation}
\label{sec:report}

The report creation process was designed to be very simple. There are two separate methods for the instructor
to choose from - the full report, and the analysis only report. Both are discussed below.

\subsection{Full Report}

The full report is to be used by those instructors who have used created their entire test using the provided 
Sweave template. The creation of the test itself is discussed in the \ref{sec:preparing} section. By simply
modifying a few global variables in the template, the instructor can create a full report to analyze the results
of the test.

The template provides a number of variables that are under the users control:

\begin{verbatim}
<<>>=
set.seed(18)
setwd(''C:\Users\Sample")
library(Sweavetest)
library(tables)
testversion <- 4
Version <- version("Student")
NumberOfVersions <- 4

if(Version == ``Report''){
scanex <- readScanex(''sample.dat'')
}
@
\end{verbatim}

To create the report, the user needs to change the following:
\begin{itemize}
\item The Version variable to ``Report''
\item The default ``sample.dat'' input for \verb!readScanex()! function to the Scantron file they wish to use.
\item The working directory must be changed to that containing the Scantron file
\end{itemize}

The variables not mentioned above should not be changed or modified in any way.

From here, everything else is achieved automatically through the built in functions.
The instructor need only process the newly modified .Rnw file, and a pdf report will be created.
This report will include all of the analysis described in the \ref{sec:analysis} section as well as
the original questions, with answer choices in non-randomized order.

An appendix is also provided at the end of the report. The appendix contains brief explanations of
all the statistics used in the report. This will allow the instructor to quickly and efficiently
look up the meaning of any of the statistics, as well as suggestions on how to improve
the question if the calculated statistics were found to be below acceptable standards.

\subsection{Analysis Only}

If the instructor did not use Sweave to create their test, analysis is still possible
using the \pkg{Sweavetest} package. 

\subsection{Report Without Using A Scantron}

\section{Cheating Detection}
\label{sec:cheating}


\section{Future Directions}

\section*{Acknowledgments}

This research was supported by an NSERC Discovery Grant to the first author, and an
NSERC Undergraduate Summer Research Award to the second author.

\section{Not covered yet}

Update this list as we cover things.

Still need to document

 [1] "answerCorrelations"          "answerMatrix"       "answerPlots"        "clean"             
 [6]          "getglobal"          "grades"                              
[11]       "mergeLists"                         
[16] "nominalRoll"        "perms"                "readScanex"           
[26] "versioncodes"       "wrongKey"   


\bibliography{Sweavetest}

\end{document}
